{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U yolo5face\n",
    "# !pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from yolo5face.get_model import get_model\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  유사도 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 폴더 경로\n",
    "folder_path = r\"C:\\Users\\ben81\\zflip_random2\"\n",
    "\n",
    "# EfficientNet 모델 로드 및 임베딩 벡터 추출 레이어 설정\n",
    "base_model = models.efficientnet_b0(pretrained=True)\n",
    "base_model.classifier[1] = nn.Identity()  # Remove the classification layer\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_image_embedding(image_path, model, device):\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 임베딩 벡터 생성\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings_from_folder(folder_path, model, device):\n",
    "    embeddings = []\n",
    "    image_paths = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            embedding = get_image_embedding(image_path, model, device)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                image_paths.append(image_path)\n",
    "    return np.array(embeddings), image_paths\n",
    "\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        if idx < 200:\n",
    "            print(\"=================group {}=================\".format(idx))\n",
    "            plt.figure(figsize=(10,10))\n",
    "            for i, image_path in enumerate(group):\n",
    "                plt.subplot(1, len(group), i + 1)\n",
    "                img = Image.open(image_path)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, base_model, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "# 유사도 0.775 이상인 그룹 생성\n",
    "threshold = 0.775\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "print(device)\n",
    "plot_image_groups(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. blurring 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture\n",
    "class MobileNetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetClassifier, self).__init__()\n",
    "        self.model = models.mobilenet_v2(pretrained=True)\n",
    "        self.model.classifier[1] = nn.Linear(self.model.last_channel, 2)  # Assuming 2 classes: blur and sharp\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# Initialize your model\n",
    "blur_model = MobileNetClassifier()\n",
    "\n",
    "# mobilenet_centered_softblurred_scene_laplacian\n",
    "model_path = r\"C:\\Users\\ben81\\GitHub\\pickle_archive\\blur\\models\\mobilenet_centered_softblurred_scene_laplacian.pth\"\n",
    "\n",
    "# Load the saved blur_model state_dict\n",
    "blur_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Device 설정 (GPU 또는 CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "blur_model.to(device)  # 모델을 GPU 또는 CPU로 전송\n",
    "\n",
    "def predict_blur(blur_model, image_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    image = Image.open(image_path).convert('RGB')  # RGB로 변환\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 이미지를 GPU 또는 CPU로 전송\n",
    "\n",
    "    # 모델 예측\n",
    "    blur_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = blur_model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "    # 결과 출력\n",
    "    classes = ['sharp','blur']\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    if predicted_class == 'blur':\n",
    "        # blur 사진 테스트용 -> 바로 사진 print\n",
    "        # print(image_path)\n",
    "        # img = cv2.imread(image_path,cv2.IMREAD_ANYCOLOR)\n",
    "        # image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # plt.imshow(image_rgb)\n",
    "        # plt.axis('off')  # 축 제거\n",
    "        # plt.show()\n",
    "\n",
    "        # blur된 사진 경로 return\n",
    "        return image_path\n",
    "    elif predicted_class == 'sharp':\n",
    "        return None\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\ben81\\GitHub\\Pickle-DL\\picklework\\eyeclosing\\zflip_camera\"\n",
    "blurred_files = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(path, i)\n",
    "        try:\n",
    "            blurred_path = predict_blur(blur_model, image_path)\n",
    "            if blurred_path is not None:\n",
    "                blurred_files.append(blurred_path)\n",
    "        except:\n",
    "            print('error')\n",
    "\n",
    "# print(blurred_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in blurred_files:\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"{image_path}을(를) 로드하는 데 실패했습니다.\")\n",
    "        continue\n",
    "\n",
    "    # BGR 이미지를 RGB로 변환\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 이미지 표시\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(image_path)\n",
    "    plt.axis('off')  # 축 숫자와 눈금 끄기\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Eye closing 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EyeStateDetector:\n",
    "    def __init__(self, images, model_path):\n",
    "        self.images = images\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.yolo_model = self.load_yolo_model()\n",
    "        self.efficientnet_model = self.load_efficientnet_model(model_path)\n",
    "        self.class_names = ['ClosedFace', 'OpenFace']\n",
    "\n",
    "    def load_yolo_model(self):\n",
    "        model = get_model(\"yolov5n\", device=self.device, min_face=24)\n",
    "        return model\n",
    "\n",
    "    def load_efficientnet_model(self, model_path):\n",
    "        net = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "        num_features = net._fc.in_features\n",
    "        net._fc = nn.Linear(num_features, 2)\n",
    "        net.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        net = net.to(self.device)\n",
    "        net.eval()\n",
    "\n",
    "        return net\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).convert('RGB')\n",
    "        image = preprocess(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "    def face_detection(self, image):\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        boxes, key_points, scores = self.yolo_model(rgb_image, target_size=512)\n",
    "        faces = []\n",
    "        if len(boxes) > 0:\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                face_image = image[y1:y2, x1:x2]\n",
    "                faces.append(face_image)\n",
    "        return faces\n",
    "\n",
    "    def eye_detection(self, face_image):\n",
    "        image = self.preprocess_image(face_image).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.efficientnet_model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        return self.class_names[preds.item()]\n",
    "\n",
    "    def predict(self):\n",
    "        results = {}\n",
    "\n",
    "        for image_name, image in self.images.items():\n",
    "            faces = self.face_detection(image)\n",
    "            if not faces:\n",
    "                results[image_name] = False\n",
    "                continue\n",
    "\n",
    "            eye_state = False\n",
    "            for face in faces:\n",
    "                eye_state = self.eye_detection(face)\n",
    "                if eye_state == 'ClosedFace':\n",
    "                    eye_state = True\n",
    "                    break\n",
    "\n",
    "            results[image_name] = eye_state\n",
    "\n",
    "        return results\n",
    "\n",
    "# Function to load all images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                images[filename] = image\n",
    "    return images\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r'C:\\Users\\ben81\\zflip_random2'  # Replace with the actual folder path\n",
    "model_path = r'C:\\Users\\ben81\\zflip_random1'\n",
    "\n",
    "# Load all images from the folder\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Initialize the EyeStateDetector\n",
    "detector = EyeStateDetector(images, model_path)\n",
    "\n",
    "# Predict eye states\n",
    "results = detector.predict()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 지헌 Eye closing 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import filterfalse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "\n",
    "class EyeStateDetector:\n",
    "    def __init__(self, images, model_path):\n",
    "        self.images = images\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.yolo_model = self.load_yolo_model()\n",
    "        self.efficientnet_model = self.load_efficientnet_model(model_path)\n",
    "        self.class_names = ['ClosedFace', 'OpenFace']\n",
    "\n",
    "    def load_yolo_model(self):\n",
    "        model = YOLO(\"picklework/eyeclosing/yolov8n-face.pt\")  # 모델 파일 경로 수정\n",
    "        return model\n",
    "\n",
    "    def load_efficientnet_model(self, model_path):\n",
    "        net = models.efficientnet_b0(pretrained=True)\n",
    "        in_features = net.classifier[1].in_features\n",
    "        net.classifier[1] = nn.Linear(in_features, 2)\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        net.to(self.device)\n",
    "        net.eval()\n",
    "        return net\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).convert('RGB')\n",
    "        image = preprocess(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "    def face_detection(self, image):\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.yolo_model.predict(source=rgb_image, conf=0.6, max_det=15, verbose=False)\n",
    "\n",
    "        faces = []\n",
    "        for result in results:\n",
    "            for bbox in result.boxes.xyxy:\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                face_width, face_height = x2 - x1, y2 - y1\n",
    "\n",
    "                # 최소 얼굴 크기 필터링\n",
    "                if face_width >= 200 and face_height >= 200:\n",
    "                    face_image = image[y1:y2, x1:x2]\n",
    "                    faces.append(face_image)\n",
    "        return faces\n",
    "\n",
    "    def eye_detection(self, face_image):\n",
    "        image = self.preprocess_image(face_image).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.efficientnet_model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        return self.class_names[preds.item()]\n",
    "\n",
    "    def predict(self):\n",
    "        results = {}\n",
    "\n",
    "        for image_name, image in self.images.items():\n",
    "            faces = self.face_detection(image)\n",
    "            if not faces:\n",
    "                results[image_name] = False\n",
    "                continue\n",
    "\n",
    "            eye_state = False\n",
    "            for face in faces:\n",
    "                eye_state = self.eye_detection(face)\n",
    "                if eye_state == 'ClosedFace':\n",
    "                    eye_state = True\n",
    "                    break\n",
    "\n",
    "            results[image_name] = eye_state\n",
    "\n",
    "        return results\n",
    "\n",
    "# Function to load all images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                images[filename] = image\n",
    "    return images\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r\"C:\\Users\\ben81\\GitHub\\Pickle-DL\\picklework\\eyeclosing\\zflip_camera\"  # Replace with the actual folder path\n",
    "model_path = r\"C:\\Users\\ben81\\GitHub\\Pickle-DL\\picklework\\eyeclosing\\models\\b0_3rd_rgbfinal_model.pth\"\n",
    "\n",
    "# Load all images from the folder\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Initialize the EyeStateDetector\n",
    "detector = EyeStateDetector(images, model_path)\n",
    "\n",
    "# Predict eye states\n",
    "results = detector.predict()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "for filename, result in results.items():\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # 이미지 읽기\n",
    "        img = mpimg.imread(file_path)\n",
    "        \n",
    "        # 이미지 표시\n",
    "        if result == True:\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'{filename}: {result}')\n",
    "            plt.axis('off')  # 축 숨기기\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(f'파일을 찾을 수 없습니다: {file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 흑백모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "\n",
    "class EyeStateDetector:\n",
    "    def __init__(self, images, model_path):\n",
    "        self.images = images\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.yolo_model = self.load_yolo_model()\n",
    "        self.efficientnet_model = self.load_efficientnet_model(model_path)\n",
    "        self.class_names = ['ClosedFace', 'OpenFace']\n",
    "\n",
    "    def load_yolo_model(self):\n",
    "        model = YOLO(\"picklework/eyeclosing/yolov8n-face.pt\")  # 모델 파일 경로 수정\n",
    "        return model\n",
    "\n",
    "    def load_efficientnet_model(self, model_path):\n",
    "        weights = models.EfficientNet_B0_Weights.DEFAULT\n",
    "        net = models.efficientnet_b0(weights=weights)\n",
    "        net.features[0][0] = nn.Conv2d(1, net.features[0][0].out_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        in_features = net.classifier[1].in_features\n",
    "        net.classifier[1] = nn.Linear(in_features, 2)\n",
    "        net.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "\n",
    "        net.to(self.device)\n",
    "        net.eval()\n",
    "        return net\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(256),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])  # 흑백 이미지 정규화\n",
    "        ])\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))  # 이미지를 흑백으로 변환\n",
    "        image = preprocess(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "    def face_detection(self, image):\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.yolo_model.predict(source=rgb_image, conf=0.65, max_det=15, verbose=False)\n",
    "\n",
    "        faces = []\n",
    "        for result in results:\n",
    "            for bbox in result.boxes.xyxy:\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                face_width, face_height = x2 - x1, y2 - y1\n",
    "\n",
    "                # 최소 얼굴 크기 필터링\n",
    "                if face_width >= 200 and face_height >= 200:\n",
    "                    face_image = image[y1:y2, x1:x2]\n",
    "                    faces.append(face_image)\n",
    "        return faces\n",
    "\n",
    "    def eye_detection(self, face_image):\n",
    "        image = self.preprocess_image(face_image).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.efficientnet_model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        return self.class_names[preds.item()]\n",
    "\n",
    "    def predict(self):\n",
    "        results = {}\n",
    "\n",
    "        for image_name, image in self.images.items():\n",
    "            faces = self.face_detection(image)\n",
    "            if not faces:\n",
    "                results[image_name] = False\n",
    "                continue\n",
    "\n",
    "            eye_state = False\n",
    "            for face in faces:\n",
    "                eye_state = self.eye_detection(face)\n",
    "                if eye_state == 'ClosedFace':\n",
    "                    eye_state = True\n",
    "                    break\n",
    "\n",
    "            results[image_name] = eye_state\n",
    "\n",
    "        return results\n",
    "\n",
    "# Function to load all images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                images[filename] = image\n",
    "    return images\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r\"C:\\Users\\ben81\\GitHub\\Pickle-DL\\picklework\\eyeclosing\\zflip_camera\"  # Replace with the actual folder path\n",
    "model_path = r\"C:\\Users\\ben81\\GitHub\\Pickle-DL\\picklework\\eyeclosing\\models\\b0_3rd_gray.pth\"\n",
    "\n",
    "# Load all images from the folder\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Initialize the EyeStateDetector\n",
    "detector = EyeStateDetector(images, model_path)\n",
    "\n",
    "# Predict eye states\n",
    "results = detector.predict()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "for filename, result in results.items():\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # 이미지 읽기\n",
    "        img = mpimg.imread(file_path)\n",
    "        \n",
    "        # 이미지 표시\n",
    "        if result == True:\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'{filename}: {result}')\n",
    "            plt.axis('off')  # 축 숨기기\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(f'파일을 찾을 수 없습니다: {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pickle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
