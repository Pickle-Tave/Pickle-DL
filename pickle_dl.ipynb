{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U yolo5face\n",
    "# !pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from yolo5face.get_model import get_model\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  유사도 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 폴더 경로\n",
    "folder_path = r\"\"\n",
    "\n",
    "# EfficientNet 모델 로드 및 임베딩 벡터 추출 레이어 설정\n",
    "base_model = models.efficientnet_b0(pretrained=True)\n",
    "base_model.classifier[1] = nn.Identity()  # Remove the classification layer\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_image_embedding(image_path, model, device):\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 임베딩 벡터 생성\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            embedding_vector = model(img_tensor).cpu().numpy().flatten()\n",
    "        return embedding_vector\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def get_embeddings_from_folder(folder_path, model, device):\n",
    "    embeddings = []\n",
    "    image_paths = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            embedding = get_image_embedding(image_path, model, device)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                image_paths.append(image_path)\n",
    "    return np.array(embeddings), image_paths\n",
    "\n",
    "def plot_image_groups(groups):\n",
    "    for idx, group in enumerate(groups):\n",
    "        if idx < 200:\n",
    "            print(\"=================group {}=================\".format(idx))\n",
    "            plt.figure(figsize=(10,10))\n",
    "            for i, image_path in enumerate(group):\n",
    "                plt.subplot(1, len(group), i + 1)\n",
    "                img = Image.open(image_path)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# 폴더 내 모든 이미지에 대한 임베딩 벡터 생성\n",
    "embeddings, image_paths = get_embeddings_from_folder(folder_path, base_model, device)\n",
    "\n",
    "# FAISS를 이용한 코사인 유사도 측정\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "D, I = index.search(embeddings, k=len(embeddings))  # 모든 이미지에 대해 유사도 측정\n",
    "\n",
    "# 유사도 0.775 이상인 그룹 생성\n",
    "threshold = 0.775\n",
    "groups = []\n",
    "visited = set()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in visited:\n",
    "        continue\n",
    "    group = [image_paths[i]]\n",
    "    visited.add(i)\n",
    "    for j in range(1, len(I[i])):\n",
    "        if D[i][j] >= threshold and I[i][j] not in visited:\n",
    "            group.append(image_paths[I[i][j]])\n",
    "            visited.add(I[i][j])\n",
    "    groups.append(group)\n",
    "\n",
    "# 결과 출력\n",
    "print(device)\n",
    "plot_image_groups(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. blurring 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture\n",
    "class MobileNetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetClassifier, self).__init__()\n",
    "        self.model = models.mobilenet_v2(pretrained=True)\n",
    "        self.model.classifier[1] = nn.Linear(self.model.last_channel, 2)  # Assuming 2 classes: blur and sharp\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# Initialize your model\n",
    "blur_model = MobileNetClassifier()\n",
    "\n",
    "# mobilenet_centered_softblurred_scene_laplacian\n",
    "model_path = './mobilenet_blurred.pth'\n",
    "\n",
    "# Load the saved blur_model state_dict\n",
    "blur_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# 이미지 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Device 설정 (GPU 또는 CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "blur_model.to(device)  # 모델을 GPU 또는 CPU로 전송\n",
    "\n",
    "def predict_blur(blur_model, image_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    image = Image.open(image_path).convert('RGB')  # RGB로 변환\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 이미지를 GPU 또는 CPU로 전송\n",
    "\n",
    "    # 모델 예측\n",
    "    blur_model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = blur_model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "    # 결과 출력\n",
    "    classes = ['sharp','blur']\n",
    "    predicted_class = classes[predicted.item()]\n",
    "    if predicted_class == 'blur':\n",
    "        # blur 사진 테스트용 -> 바로 사진 print\n",
    "        # print(image_path)\n",
    "        # img = cv2.imread(image_path,cv2.IMREAD_ANYCOLOR)\n",
    "        # image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # plt.imshow(image_rgb)\n",
    "        # plt.axis('off')  # 축 제거\n",
    "        # plt.show()\n",
    "\n",
    "        # blur된 사진 경로 return\n",
    "        return image_path\n",
    "    elif predicted_class == 'sharp':\n",
    "        return None\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\ben81\\zflip_camera\"\n",
    "blurred_files = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    if i.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(path, i)\n",
    "        try:\n",
    "            blurred_path = predict_blur(blur_model, image_path)\n",
    "            if blurred_path not None:\n",
    "                blurred_files.append(blurred_path)\n",
    "        except:\n",
    "            print('error')\n",
    "\n",
    "print(blurred_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Eye closing 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeStateDetector:\n",
    "    def __init__(self, images, model_path):\n",
    "        self.images = {}\n",
    "        self.yolo_model = self.load_yolo_model()\n",
    "        self.efficientnet_model = self.load_efficientnet_model(model_path)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.class_names = ['ClosedFace', 'OpenFace']\n",
    "\n",
    "    def load_yolo_model(self):\n",
    "        model = get_model(\"yolov5n\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\", min_face=24)\n",
    "        return model\n",
    "\n",
    "    def load_efficientnet_model(self, model_path):\n",
    "        net = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "        num_features = net._fc.in_features\n",
    "        net._fc = nn.Linear(num_features, 2)\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "        net = net.to(self.device)\n",
    "        net.eval()\n",
    "\n",
    "        return net\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)).convert('RGB')\n",
    "        image = preprocess(image)\n",
    "        image = image.unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "    def face_detection(self, image):\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        boxes, key_points, scores = self.yolo_model(rgb_image, target_size=512)\n",
    "        faces = []\n",
    "        if len(boxes) > 0:\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                face_image = image[y1:y2, x1:x2]\n",
    "                faces.append(face_image)\n",
    "        return faces\n",
    "\n",
    "    def eye_detection(self, face_image):\n",
    "        image = self.preprocess_image(face_image).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.efficientnet_model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        return self.class_names[preds.item()]\n",
    "\n",
    "    def predict(self, image):\n",
    "        results = {}\n",
    "\n",
    "        for image_name, image in self.images.items():\n",
    "            faces = self.face_detection(image)\n",
    "            if not faces:\n",
    "                results[image_name] = False\n",
    "                continue\n",
    "\n",
    "            eye_state = False\n",
    "            for face in faces:\n",
    "                # 눈 검출 및 상태 예측\n",
    "                eye_state = self.eye_detection(face)\n",
    "                if eye_state == 'ClosedFace':\n",
    "                    eye_state = True\n",
    "                    break\n",
    "\n",
    "            results[image_name] = eye_state\n",
    "\n",
    "        return results\n",
    "# Function to load all images from a folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                images[filename] = image\n",
    "    return images\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r'C:\\Users\\ben81\\GitHub\\Pickle-DL'  # Replace with the actual folder path\n",
    "model_path = 'effnet_b3.pth'  \n",
    "\n",
    "# Load all images from the folder\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Initialize the EyeStateDetector\n",
    "detector = EyeStateDetector(images, model_path)\n",
    "\n",
    "# Predict eye states\n",
    "results = detector.predict()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pickle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
